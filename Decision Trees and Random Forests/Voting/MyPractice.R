str(gerber)
summary(gerber$yob)
table(gerber$sex)
table(gerber$voting)
#108696/(108696+235388)
table(gerber$hawthorne, gerber$voting)
#12316/(12316+25888)
table(gerber$civicduty, gerber$voting)
#12021/(12021+26197)
table(gerber$neighbors, gerber$voting)
#14438/(14438+23763)
tapply(gerber$voting, gerber$neighbors, mean)
table(gerber$self, gerber$voting)
#13191/(13191+25027)
table(gerber$control, gerber$voting)
#56730/(56730+134513)

#Logistic Regression
gerberLog <- glm(voting ~ civicduty + hawthorne + self + neighbors, data = gerber, family = "binomial")
summary(gerberLog)
table(gerber$voting, gerberLog$fitted.values > 0.3)
Accuracy <- (134513+51966)/nrow(gerber)
table(gerber$voting, gerberLog$fitted.values > 0.5)
Accuracy <- (235388)/nrow(gerber)
table(gerber$voting)
BaselineAccuracy <- (235388)/nrow(gerber)

library(ROCR)
ROCRPred <- prediction(gerberLog$fitted.values, gerber$voting)
AUC <- as.numeric(performance(ROCRPred, "auc")@y.values)

gerberTree <- rpart(voting ~ civicduty + hawthorne + self + neighbors, data = gerber)
prp(gerberTree)
gerberTree2 <- rpart(voting ~ civicduty + hawthorne + self + neighbors, data = gerber, cp = 0.0)
prp(gerberTree2)
gerberTree3 <- rpart(voting ~ civicduty + hawthorne + self + neighbors + sex, data = gerber, cp = 0.0)
prp(gerberTree3)
gerberTree4 <- rpart(voting ~ control, data = gerber, cp = 0.0)
prp(gerberTree4, digits = 6)
abs(0.296638 - 0.34)
gerberTree5 <- rpart(voting ~ control + sex, data = gerber, cp = 0.0)
prp(gerberTree5, digits = 6)

gerberLog2 <- glm(voting ~ control + sex, data = gerber, family = "binomial")
summary(gerberLog2)
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(gerberLog2, newdata=Possibilities, type="response")
abs(0.290456 - 0.2908065)
gerberLog3 <- glm(voting ~ control + sex + sex:control, data = gerber, family = "binomial")
summary(gerberLog3)
predict(gerberLog3, newdata=Possibilities, type="response")
abs(0.290456 - 0.2904558)

library(caTools)
split <- sample.split(gerber$voting, SplitRatio = 0.6)
Train <- subset(gerber, split == TRUE)
Test <- subset(gerber, split == FALSE)
TrainTree <- rpart(voting ~ civicduty + hawthorne + self + neighbors + sex, data = Train, cp = 0)
prp(TrainTree)
predictTest <- predict(TrainTree, newdata = Test)
table(Test$voting, predictTest > 0.345)

library(caret)
library(e1071)
tr.Control <- trainControl(method = "cv", number = 10)
cp.grid <- expand.grid(.cp = seq(0,0.01, 0.001))
TrainCVTree <- train(voting ~ civicduty + hawthorne + self + neighbors + sex, data = Train, method = 'rpart', tuneGrid = cp.grid, trControl = tr.Control)
Train$voting <- as.factor(Train$voting)
Test$voting <- as.factor(Test$voting)
TrainCVTree <- train(voting ~ civicduty + hawthorne + self + neighbors + sex, data = Train, method = 'rpart', tuneGrid = cp.grid, trControl = tr.Control)
TrainCVTree
CVTree <- TrainCVTree$finalModel
prp(CVTree)
TestCVPredict <- predict(TrainCVTree, newdata = Test)
table(Test$voting, TestCVPredict > 0.345)

library(randomForest)
TrainForest <- randomForest(voting ~ civicduty + hawthorne + self + neighbors + sex, data = Train, nodesize = 0, ntree = 200)
prp(TrainForest)
TestForestPredict <- predict(TrainForest, newdata = Test)
table(Test$voting, TestForestPredict > 0.33)